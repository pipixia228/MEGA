链接：
	Parper：[]()https://arxiv.org/abs/2303.12077
	code:[]()https://github.com/hustvl/VAD
# 核心点
1. 完全矢量化建模
2. 查询交互==隐式==利用矢量化场景信息；规划约束==显式==利用矢量化场景信息
# 框架
![[VAD框架.png]]
### 1. 输入：多帧、多视角图像
### 2. Backbone（环境信息处理（感知））:Bev Encoder==编码==图像并将图像特征投影到BEV Features
### 3. Vectorized Scene Learning（矢量化场景学习）
#### 3.1 map query
1. 从BEV Feature中提取出车道分隔线、道路边界和人行横道。车道分隔线提供方向信息，道路边界指示可行驶区域。
2. 矢量地图信息还充当了==决策器的角色==，为规划提供左转、右转、直行指令
#### 3.1 agent query
1. 依据注意力机制执行车与车的交互==（背景车的行为预测）==
2. 以概率分数表征背景车的行为意图（为后续自车的轨迹规划提供背景信息）==求解场景==
### 4. Planning Inferring Phase（与矢量化信息交互规划）
1. 自车与背景车交互查询得到`k、v、q`==（解码）==
2. 自车与地图交互查询得到`k、v、q`==（解码）==
3. 输入给`planner Transformer`
### 5. Planning Training Phase（引入矢量化约束限制实例级别的轨迹）
1. 自车与背景车的交互约束：选择高置信度的预测轨迹作为背景车的预测轨迹
2. 自车与地图边界的约束：使最终轨迹远离道路边界
3. 自车车道信息约束：定义损失使自车行驶方向与车道矢量相匹配
### 6. End-to-End Learning（端到端训练）
1. 矢量化场景学习损失（步骤3）
2. 矢量化约束损失（步骤5）
3. 模仿学习损失（规划输出与真实轨迹的差异）




**1.15task：VAD梳理、UniAD梳理、相关前置知识、VADv2梳理**
论文详细推导
